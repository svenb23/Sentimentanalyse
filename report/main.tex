\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{amsmath}

\usepackage[scaled]{helvet}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[a4paper, top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{setspace}
\setstretch{1.5}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

\usepackage{microtype}
\sloppy
\hyphenpenalty=1000
\tolerance=3000

\renewcommand{\footnotesize}{\fontsize{10}{12}\selectfont}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\usepackage{titlesec}
\titleformat{\section}{\normalfont\fontsize{12}{14}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\fontsize{12}{14}\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalfont\fontsize{12}{14}\bfseries}{\thesubsubsection}{1em}{}

\usepackage[
  colorlinks=true,
  linkcolor=black,
  citecolor=blue,
  filecolor=black,
  urlcolor=blue
]{hyperref}
\usepackage[capitalise,nameinlink]{cleveref}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{\thepage}

\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{references.bib}

\usepackage{titling}

\usepackage{acronym}

\usepackage{caption}
\usepackage{threeparttable}
\captionsetup[table]{
    font=small,
    skip=10pt,
    labelfont=bf
}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

\begin{titlepage}
    \thispagestyle{empty}
    \centering
    \vspace*{5cm}
    {\Huge\bfseries Projekt: NLP DLBAIPNLP01\_D \par}
    \vspace{1cm}
    {\Large Projektbericht \par}
    \vspace{0.5cm}
    {\large Studiengang: Angewandte Künstliche Intelligenz \par}
    \vspace{0.5cm}
    {\large Sven Behrens \par}
    \vspace{0.5cm}
    {\large Matrikelnummer: 42303511 \par}
    \vspace{0.5cm}
    {\large Tutor: Prof. Dr. Maja Popovic \par}
    \vspace{0.5cm}
    {\large \today \par}
\end{titlepage}

\pagenumbering{Roman}
\setcounter{page}{1}

\tableofcontents
\newpage

\listoffigures
\addcontentsline{toc}{section}{Abbildungsverzeichnis}
\newpage

\listoftables
\addcontentsline{toc}{section}{Tabellenverzeichnis}
\newpage

\section*{Abkürzungsverzeichnis}
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
\begin{acronym}[DistilBERT]
    \acro{API}{Application Programming Interface}
\end{acronym}
\newpage

\pagenumbering{arabic}
\setcounter{page}{1}

\section{Einleitung}
Durch die zunehmende Digitalisierung werden Benutzerbewertungen sowohl zur Beurteilung
von Produkten als auch in sozialen Medien immer wichtiger, sowohl für Kunden, um einen
schnellen Überblick zu bekommen, als auch für Unternehmen, um Feedback systematisch auszuwerten.
So werden täglich Millionen von Nutzermeinungen erzeugt, deren manuelle Analyse
längst nicht mehr praktikabel ist. Die automatisierte
Sentimentanalyse von Produktrezensionen stellt dabei eine zentrale Herausforderung
im Bereich des Natural Language Processing dar, deren Bewältigung für Unternehmen
maßgeblich zur Produktverbesserung und Kundenzufriedenheitsanalyse beiträgt.
Vor diesem Hintergrund wurde im Rahmen des Moduls „Projekt: NLP" an der IU
Internationalen Hochschule ein umfassendes System zur Sentimentanalyse von
Amazon-Produktbewertungen entwickelt, das sowohl klassische
Machine-Learning-Verfahren als auch moderne Transformer-Architekturen systematisch
vergleicht.

Das primäre Projektziel bestand in der Entwicklung und dem Vergleich verschiedener
Klassifikationsansätze zur automatischen Sentiment-Erkennung aus englischsprachigen
Produktrezensionen. Die zentrale Forschungsfrage konzentrierte sich darauf, wie sich
traditionelle Machine-Learning-Verfahren, mit Modellen wie Logistic Regression gegenüber
modernen vortrainierten Sprachmodellen wie DistilBERT hinsichtlich
Klassifikationsgenauigkeit und Praxistauglichkeit verhalten.

Die Datenbasis bildeten Amazon-Produktrezensionen aus drei Kategorien, Automotive,
Pet Supplies und Video Games, mit insgesamt 150.000 Datensätzen, die stratifiziert
in Trainings- (70\%), Validierungs- (15\%) und Testdaten (15\%) aufgeteilt wurden.
Jede Rezension umfasst Titel, Text und eine Sternebewertung von 1 bis 5, wobei
sowohl eine 5-Klassen-Klassifikation als auch eine aggregierte 
3-Klassen-Sentimentanalyse (negativ, neutral, positiv) untersucht wurden.

Die methodische Vorgehensweise gliederte sich in mehrere aufeinander aufbauende
Phasen. Nach einer initialen Datenaufbereitung mit Textbereinigung,
Lemmatisierung und Stopwort-Entfernung erfolgte zunächst die Implementierung
klassischer Modelle unter Verwendung von TF-IDF-Vektorisierung mit
bis zu 20.000 Features. Hierbei wurden Logistic Regression, Naive Bayes, SVM,
Random Forest und Gradient Boosting systematisch evaluiert. Parallel dazu wurde 
ein Fine-Tuning des DistilBERT-Modells auf dem vollständigen Trainingsdatensatz 
durchgeführt sowie ein vortrainiertes BERT-Modell für Sentimentanalyse im 
Zero-Shot-Modus getestet.

Der vorliegende Projektbericht dokumentiert systematisch den gesamten
Entwicklungsprozess. Nach dieser Einleitung folgt die detaillierte Beschreibung 
der Methodik, einschließlich der Datenaufbereitung sowie der 
Modellauswahl und -konfiguration. Anschließend werden die Trainingsabläufe und 
deren Ergebnisse ausführlich dargestellt, wobei das beste Modell (DistilBERT)
eine Testgenauigkeit von 80,91\% erreichte, während die klassische Logistic
Regression mit 76,66\% konkurrenzfähige Referenzleistung erzielte.
Abschließend werden die gewonnenen Erkenntnisse in einem Fazit zusammengefasst
und kritisch reflektiert.


\section{Hauptteil}
\subsection{Hardwareauswahl}
Zu Projektbeginn standen drei Alternativen zur Verfügung: ein MacBook Pro mit Apple-M2-Chip,
ein Windows-PC mit NVIDIA RTX 3060 sowie verschiedene Cloud-Computing-Anbieter.

Für das Training der klassischen Machine-Learning-Modelle wie Logistic Regression,
Naive Bayes und SVM war sowohl das MacBook als auch der Windows-PC ausreichend,
da diese Verfahren primär CPU-basiert arbeiten. Für das Fine-Tuning der BERT-Modelle
schied das MacBook jedoch aufgrund der fehlenden CUDA-Unterstützung aus.

Das Training wurde daher auf dem Windows-11-Computer (Intel i7-12700K, 32 GB DDR5,
NVIDIA RTX 3060 mit 12 GB VRAM) durchgeführt. Da selbst das längste Training
(DistilBERT auf 105.000 Samples) mit etwa zwei Tagen in einem akzeptablen Rahmen blieb,
waren zusätzliche Cloud-Lösungen nicht erforderlich. 

\subsection{Projektumgebung einrichten}  
\subsection{Datenbeschaffung}  
\subsection{Modellauswahl}
\subsubsection{Evaluierung der Modellarchitekturen}
\subsubsection{Iterative Modellentwicklung}
\subsection{Trainingslaufe}

\section{Fazit}
\subsection{Zielerreichung und Projektergebnisse}
\subsection{Kritische Reflexion und gewonnene Erkenntnisse}
\subsection{Verbesserungspotenziale und Optimierungsansätze}
\subsection{Ausblick}
\newpage

\printbibliography
\addcontentsline{toc}{section}{Literaturverzeichnis}

\newpage
\section*{Verzeichnis der Anhänge}
\addcontentsline{toc}{section}{Verzeichnis der Anhänge}

\appendix
\section*{Anhang}
\addcontentsline{toc}{section}{Anhang}

\end{document}
