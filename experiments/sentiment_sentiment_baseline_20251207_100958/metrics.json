{
  "validation": {
    "accuracy": 0.8790222222222223,
    "precision_macro": 0.7527019044026192,
    "recall_macro": 0.6276565043383742,
    "f1_macro": 0.6507164041942155,
    "precision_weighted": 0.8614596008717572,
    "recall_weighted": 0.8790222222222223,
    "f1_weighted": 0.8612373550487734,
    "confusion_matrix": [
      [
        2909,
        86,
        868
      ],
      [
        438,
        243,
        866
      ],
      [
        366,
        98,
        16626
      ]
    ],
    "classification_report": {
      "0": {
        "precision": 0.7834635065984379,
        "recall": 0.753041677452757,
        "f1-score": 0.7679514255543822,
        "support": 3863.0
      },
      "1": {
        "precision": 0.5690866510538641,
        "recall": 0.1570782159017453,
        "f1-score": 0.24620060790273557,
        "support": 1547.0
      },
      "2": {
        "precision": 0.9055555555555556,
        "recall": 0.9728496196606202,
        "f1-score": 0.9379971791255289,
        "support": 17090.0
      },
      "accuracy": 0.8790222222222223,
      "macro avg": {
        "precision": 0.7527019044026192,
        "recall": 0.6276565043383742,
        "f1-score": 0.6507164041942155,
        "support": 22500.0
      },
      "weighted avg": {
        "precision": 0.8614596008717572,
        "recall": 0.8790222222222223,
        "f1-score": 0.8612373550487734,
        "support": 22500.0
      }
    }
  },
  "test": {
    "accuracy": 0.8833333333333333,
    "precision_macro": 0.779204868880074,
    "recall_macro": 0.6415620563416876,
    "f1_macro": 0.6694229873380019,
    "precision_weighted": 0.8696099718252495,
    "recall_weighted": 0.8833333333333333,
    "f1_weighted": 0.8672128001036714,
    "confusion_matrix": [
      [
        2937,
        79,
        848
      ],
      [
        426,
        295,
        826
      ],
      [
        359,
        87,
        16643
      ]
    ],
    "classification_report": {
      "0": {
        "precision": 0.7890918860827512,
        "recall": 0.7600931677018633,
        "f1-score": 0.7743211178486686,
        "support": 3864.0
      },
      "1": {
        "precision": 0.6399132321041214,
        "recall": 0.19069166127989656,
        "f1-score": 0.29382470119521914,
        "support": 1547.0
      },
      "2": {
        "precision": 0.9086094884533493,
        "recall": 0.9739013400433028,
        "f1-score": 0.940123142970118,
        "support": 17089.0
      },
      "accuracy": 0.8833333333333333,
      "macro avg": {
        "precision": 0.779204868880074,
        "recall": 0.6415620563416876,
        "f1-score": 0.6694229873380019,
        "support": 22500.0
      },
      "weighted avg": {
        "precision": 0.8696099718252495,
        "recall": 0.8833333333333333,
        "f1-score": 0.8672128001036714,
        "support": 22500.0
      }
    }
  },
  "test_Automotive": {
    "accuracy": 0.8900252357550803,
    "precision_macro": 0.7881793514272162,
    "recall_macro": 0.6403006846125382,
    "f1_macro": 0.6715995139701771,
    "precision_weighted": 0.8782043015947039,
    "recall_weighted": 0.8900252357550803,
    "f1_weighted": 0.8753200929425737,
    "confusion_matrix": [
      [
        886,
        25,
        277
      ],
      [
        125,
        95,
        255
      ],
      [
        124,
        22,
        5720
      ]
    ],
    "classification_report": {
      "0": {
        "precision": 0.7806167400881058,
        "recall": 0.7457912457912458,
        "f1-score": 0.7628067154541541,
        "support": 1188.0
      },
      "1": {
        "precision": 0.6690140845070423,
        "recall": 0.2,
        "f1-score": 0.3079416531604538,
        "support": 475.0
      },
      "2": {
        "precision": 0.9149072296865003,
        "recall": 0.975110808046369,
        "f1-score": 0.9440501732959234,
        "support": 5866.0
      },
      "accuracy": 0.8900252357550803,
      "macro avg": {
        "precision": 0.7881793514272162,
        "recall": 0.6403006846125382,
        "f1-score": 0.6715995139701771,
        "support": 7529.0
      },
      "weighted avg": {
        "precision": 0.8782043015947039,
        "recall": 0.8900252357550803,
        "f1-score": 0.8753200929425737,
        "support": 7529.0
      }
    }
  },
  "test_Video_Games": {
    "accuracy": 0.8826943844492441,
    "precision_macro": 0.7721206640265139,
    "recall_macro": 0.6535701980303619,
    "f1_macro": 0.6800179089889714,
    "precision_weighted": 0.8675078708425197,
    "recall_weighted": 0.8826943844492441,
    "f1_weighted": 0.8672038675123267,
    "confusion_matrix": [
      [
        1055,
        27,
        266
      ],
      [
        148,
        110,
        278
      ],
      [
        104,
        46,
        5374
      ]
    ],
    "classification_report": {
      "0": {
        "precision": 0.8071920428462127,
        "recall": 0.7826409495548962,
        "f1-score": 0.7947269303201506,
        "support": 1348.0
      },
      "1": {
        "precision": 0.6010928961748634,
        "recall": 0.20522388059701493,
        "f1-score": 0.30598052851182195,
        "support": 536.0
      },
      "2": {
        "precision": 0.9080770530584656,
        "recall": 0.9728457639391745,
        "f1-score": 0.9393462681349415,
        "support": 5524.0
      },
      "accuracy": 0.8826943844492441,
      "macro avg": {
        "precision": 0.7721206640265139,
        "recall": 0.6535701980303619,
        "f1-score": 0.6800179089889714,
        "support": 7408.0
      },
      "weighted avg": {
        "precision": 0.8675078708425197,
        "recall": 0.8826943844492441,
        "f1-score": 0.8672038675123267,
        "support": 7408.0
      }
    }
  },
  "test_Pet_Supplies": {
    "accuracy": 0.877297368769007,
    "precision_macro": 0.7808688260972194,
    "recall_macro": 0.6305300135574103,
    "f1_macro": 0.6561723822160417,
    "precision_weighted": 0.8637628941311083,
    "recall_weighted": 0.877297368769007,
    "f1_weighted": 0.8590568426028935,
    "confusion_matrix": [
      [
        996,
        27,
        305
      ],
      [
        153,
        90,
        293
      ],
      [
        131,
        19,
        5549
      ]
    ],
    "classification_report": {
      "0": {
        "precision": 0.778125,
        "recall": 0.75,
        "f1-score": 0.7638036809815951,
        "support": 1328.0
      },
      "1": {
        "precision": 0.6617647058823529,
        "recall": 0.16791044776119404,
        "f1-score": 0.26785714285714285,
        "support": 536.0
      },
      "2": {
        "precision": 0.9027167724093054,
        "recall": 0.973679592911037,
        "f1-score": 0.9368563228093871,
        "support": 5699.0
      },
      "accuracy": 0.877297368769007,
      "macro avg": {
        "precision": 0.7808688260972194,
        "recall": 0.6305300135574103,
        "f1-score": 0.6561723822160417,
        "support": 7563.0
      },
      "weighted avg": {
        "precision": 0.8637628941311083,
        "recall": 0.877297368769007,
        "f1-score": 0.8590568426028935,
        "support": 7563.0
      }
    }
  },
  "experiment_id": "sentiment_sentiment_baseline_20251207_100958",
  "sentiment_analysis": true,
  "sentiment_labels": [
    "negativ",
    "neutral",
    "positiv"
  ]
}